{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Importing Python packages to use for data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "Loading up the iron, copper, and lead data worksheet. We did some preprocessing on this to remove redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data from .csv file\n",
    "metal_data = pd.read_csv('LSP_data.csv')\n",
    "\n",
    "# for now, let's just try to predict lead result from copper and iron results\n",
    "x = pd.DataFrame(dict(copper_result=metal_data['Copper Result'].dropna(), iron_result=metal_data['Iron Result'].dropna()))\n",
    "y = metal_data['Lead Result'].values.reshape((1443, 1))\n",
    "\n",
    "# split up data (approx. 80% / 20% split for now) for training, testing datsets\n",
    "train_data, test_data = (x[:1150], y[:1150]), (x[1150:], y[1150:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1150, 293)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Linear Regression Model\n",
    "\n",
    "Using off-the-shelf scikit-learn linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fit the models\n",
    "copper_model = LinearRegression(n_jobs=8)\n",
    "copper_model.fit(train_data[0]['copper_result'].values.reshape((1150, 1)), train_data[1])\n",
    "\n",
    "iron_model = LinearRegression(n_jobs=8)\n",
    "iron_model.fit(train_data[0]['iron_result'].values.reshape((1150, 1)), train_data[1])\n",
    "\n",
    "model = LinearRegression(n_jobs=8)\n",
    "model.fit(train_data[0], train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(test_data[0]['copper_result'], test_data[1]);\n",
    "plt.title('Copper vs. Lead Results')\n",
    "plt.plot(test_data[0]['copper_result'].values.reshape((293, 1)), copper_model.predict(test_data[0]['copper_result'].values.reshape((293, 1))))\n",
    "plt.title('Model Predictions on Copper vs. Lead Results')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(test_data[0]['iron_result'], test_data[1]);\n",
    "plt.title('Iron vs. Lead Results')\n",
    "plt.plot(test_data[0]['iron_result'].values.reshape((293, 1)), iron_model.predict(test_data[0]['iron_result'].values.reshape((293, 1))))\n",
    "plt.title('Model Predictions on Iron vs. Lead Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get R^2 score of composite model on training data\n",
    "print 'R^2 score of linear regression copper model on training data:', copper_model.score(train_data[0]['copper_result'].values.reshape(1150, 1), train_data[1])\n",
    "\n",
    "# get R^2 score of composite model on test data\n",
    "print 'R^2 score of linear regression copper model on test data:', copper_model.score(test_data[0]['copper_result'].values.reshape(293, 1), test_data[1])\n",
    "# get R^2 score of composite model on training data\n",
    "\n",
    "print 'R^2 score of linear regression iron model on training data:', iron_model.score(train_data[0]['iron_result'].values.reshape(1150, 1), train_data[1])\n",
    "\n",
    "# get R^2 score of composite model on test data\n",
    "print 'R^2 score of linear regression iron model on test data:', iron_model.score(test_data[0]['iron_result'].values.reshape(293, 1), test_data[1])\n",
    "\n",
    "# get R^2 score of composite model on training data\n",
    "print 'R^2 score of linear regression model on training data:', model.score(train_data[0], train_data[1])\n",
    "\n",
    "# get R^2 score of composite model on test data\n",
    "print 'R^2 score of linear regression model on test data:', model.score(test_data[0], test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Kernel SVM Model\n",
    "\n",
    "We'll try fitting this data with support vector regressors with different kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear kernel SVM R^2 score on training data: 0.0203199287037\n",
      "Linear kernel SVM R^2 score on test data: 0.197837270486\n"
     ]
    }
   ],
   "source": [
    "linear_svr = SVR(kernel='linear')\n",
    "\n",
    "linear_svr.fit(train_data[0], train_data[1])\n",
    "\n",
    "print 'Linear kernel SVM R^2 score on training data:', linear_svr.score(train_data[0], train_data[1])\n",
    "\n",
    "print 'Linear kernel SVM R^2 score on test data:', linear_svr.score(test_data[0], test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF kernel SVM R^2 score on training data: -0.0102193408219\n",
      "RBF kernel SVM R^2 score on test data: -0.0989261126424\n"
     ]
    }
   ],
   "source": [
    "rbf_svr = SVR(kernel='rbf')\n",
    "\n",
    "rbf_svr.fit(train_data[0], train_data[1])\n",
    "\n",
    "print 'RBF kernel SVM R^2 score on training data:', rbf_svr.score(train_data[0], train_data[1])\n",
    "\n",
    "print 'RBF kernel SVM R^2 score on test data:', rbf_svr.score(test_data[0], test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poly_svr = SVR(kernel='poly', degree=2)\n",
    "\n",
    "poly_svr.fit(train_data[0][:10], train_data[1][:10])\n",
    "\n",
    "print 'Polynomial kernel SVM R^2 score on training data:', poly_svr.score(train_data[0], train_data[1])\n",
    "\n",
    "print 'Polynomial kernel SVM R^2 score on test data:', poly_svr.score(test_data[0], test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sigmoid kernel SVM R^2 score on training data: -0.018775728086\n",
      "Sigmoid kernel SVM R^2 score on test data: -0.153926739469\n"
     ]
    }
   ],
   "source": [
    "sigmoid_svr = SVR(kernel='sigmoid')\n",
    "\n",
    "sigmoid_svr.fit(train_data[0], train_data[1])\n",
    "\n",
    "print 'Sigmoid kernel SVM R^2 score on training data:', sigmoid_svr.score(train_data[0], train_data[1])\n",
    "\n",
    "print 'Sigmoid kernel SVM R^2 score on test data:', sigmoid_svr.score(test_data[0], test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Regression\n",
    "\n",
    "Fuck it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MLP regressor R^2 score on training data: -0.0947082419425\n",
      "Average MLP regressor R^2 score on test data: -0.60921001624\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=2, activation='relu', solver='adam')\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "    \n",
    "    train_scores.append(model.score(train_data[0], train_data[1]))\n",
    "    test_scores.append(model.score(test_data[0], test_data[1]))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on training data:', sum(train_scores) / float(len(train_scores))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on test data:', sum(test_scores) / float(len(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MLP regressor R^2 score on training data: 0.0190313378963\n",
      "Average MLP regressor R^2 score on test data: 0.0568200425328\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=4, activation='relu', solver='adam')\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "    \n",
    "    train_scores.append(model.score(train_data[0], train_data[1]))\n",
    "    test_scores.append(model.score(test_data[0], test_data[1]))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on training data:', sum(train_scores) / float(len(train_scores))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on test data:', sum(test_scores) / float(len(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MLP regressor R^2 score on training data: 0.0663714178264\n",
      "Average MLP regressor R^2 score on test data: 0.117112233342\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=8, activation='relu', solver='adam')\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "    \n",
    "    train_scores.append(model.score(train_data[0], train_data[1]))\n",
    "    test_scores.append(model.score(test_data[0], test_data[1]))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on training data:', sum(train_scores) / float(len(train_scores))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on test data:', sum(test_scores) / float(len(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MLP regressor R^2 score on training data: 0.0682431039035\n",
      "Average MLP regressor R^2 score on test data: 0.117773768907\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=16, activation='relu', solver='adam')\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "    \n",
    "    train_scores.append(model.score(train_data[0], train_data[1]))\n",
    "    test_scores.append(model.score(test_data[0], test_data[1]))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on training data:', sum(train_scores) / float(len(train_scores))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on test data:', sum(test_scores) / float(len(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MLP regressor R^2 score on training data: 0.0601306614141\n",
      "Average MLP regressor R^2 score on test data: 0.0688075013875\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=[16, 8], activation='relu', solver='adam')\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "    \n",
    "    train_scores.append(model.score(train_data[0], train_data[1]))\n",
    "    test_scores.append(model.score(test_data[0], test_data[1]))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on training data:', sum(train_scores) / float(len(train_scores))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on test data:', sum(test_scores) / float(len(test_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MLP regressor R^2 score on training data: 0.0713761157549\n",
      "Average MLP regressor R^2 score on test data: 0.0504977739232\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=[32, 16], activation='relu', solver='adam')\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "    \n",
    "    train_scores.append(model.score(train_data[0], train_data[1]))\n",
    "    test_scores.append(model.score(test_data[0], test_data[1]))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on training data:', sum(train_scores) / float(len(train_scores))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on test data:', sum(test_scores) / float(len(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression\n",
    "\n",
    "Last one for tonight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MLP regressor R^2 score on training data: 0.592138630647\n",
      "Average MLP regressor R^2 score on test data: -18.8791380323\n",
      "<sklearn.tree._tree.Tree object at 0x7f803800a510>\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeRegressor()\n",
    "\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    model.fit(train_data[0], train_data[1])\n",
    "    \n",
    "    train_scores.append(model.score(train_data[0], train_data[1]))\n",
    "    test_scores.append(model.score(test_data[0], test_data[1]))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on training data:', sum(train_scores) / float(len(train_scores))\n",
    "\n",
    "print 'Average MLP regressor R^2 score on test data:', sum(test_scores) / float(len(test_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Average Ridge regression R^2 score on training data: 0.0693886537958\n",
      "Average Ridge regression R^2 score on test data: 0.0854539723189\n"
     ]
    }
   ],
   "source": [
    "model = Ridge()\n",
    "\n",
    "model.fit(train_data[0], train_data[1])\n",
    "\n",
    "print 'Average Ridge regression R^2 score on training data:', model.score(train_data[0], train_data[1])\n",
    "\n",
    "print 'Average Ridge regression R^2 score on test data:', model.score(test_data[0], test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression with Hyperparameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The total space of parameters 10 is smaller than n_iter=25. For exhaustive searches, use GridSearchCV.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f5983a30969c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# creating randomized search CV object and fit it to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# report results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                           random_state=self.random_state)\n\u001b[0;32m-> 1190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dan/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchedCalls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;31m# No more tasks available in the iterator: tell caller to stop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, iterator_slice)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         )(delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n\u001b[0m\u001b[1;32m    558\u001b[0m                                   \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m                                   \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dan/anaconda3/envs/py27/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m                     \u001b[0;34m\"The total space of parameters %d is smaller \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                     \u001b[0;34m\"than n_iter=%d. For exhaustive searches, use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                     \"GridSearchCV.\" % (grid_size, self.n_iter))\n\u001b[0m\u001b[1;32m    243\u001b[0m             for i in sample_without_replacement(grid_size, self.n_iter,\n\u001b[1;32m    244\u001b[0m                                                 random_state=rnd):\n",
      "\u001b[0;31mValueError\u001b[0m: The total space of parameters 10 is smaller than n_iter=25. For exhaustive searches, use GridSearchCV."
     ]
    }
   ],
   "source": [
    "# setting parameter distribution\n",
    "param_dist = { 'alpha' : scipy.stats.expon(scale=1), 'solver' : [ 'svd', 'cholesky', 'sparse_cg', 'lsqr', 'sag' ] }\n",
    "\n",
    "# creating Ridge Regression model\n",
    "model = Ridge()\n",
    "\n",
    "# creating randomized search CV object and fit it to the training data\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=25)\n",
    "random_search.fit(train_data[0], train_data[1])\n",
    "\n",
    "# report results\n",
    "report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
